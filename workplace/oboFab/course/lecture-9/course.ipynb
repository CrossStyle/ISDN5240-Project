{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd22b9c9-eba1-4efc-8ac7-d10a756ad506",
   "metadata": {},
   "source": [
    "# 1. Initialize robot and environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c51daa-5594-4855-9976-5d18265a614f",
   "metadata": {},
   "source": [
    "## Load curobo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1062f1bf-f1e9-4fe1-83ff-d74b90265156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# cuRobo\n",
    "from curobo.cuda_robot_model.cuda_robot_model import CudaRobotModel, CudaRobotModelConfig\n",
    "from curobo.types.base import TensorDeviceType\n",
    "from curobo.types.robot import RobotConfig\n",
    "from curobo.util_file import get_robot_path, join_path, load_yaml\n",
    "from robofab.mqtt import publish_robot_trajs, publish_clear, publish_world, publish_frames, publish_grasp_object\n",
    "# convenience function to store tensor type and device\n",
    "tensor_args = TensorDeviceType()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9e43c5-983a-4e8e-9616-b34049529899",
   "metadata": {},
   "source": [
    "## Load franka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9810e99-f821-46e1-b624-30d60547e3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path of the yml file must be absolute\n",
    "from robofab import ROBOFAB_DATA_DIR\n",
    "def load_franka_kin_model(gripper_width = 0.04):\n",
    "    robot_name = \"left\"\n",
    "    config_file = load_yaml(ROBOFAB_DATA_DIR+ f\"/robot/dual_franka/fr3_franka_{robot_name}.yml\")[\"robot_cfg\"]\n",
    "    config_kinematics = config_file['kinematics']\n",
    "    config_kinematics[\"urdf_path\"] = ROBOFAB_DATA_DIR + \"/robot/dual_franka/\" + config_kinematics[\"urdf_path\"]\n",
    "    config_kinematics[\"collision_spheres\"] = ROBOFAB_DATA_DIR + \"/robot/dual_franka/\" + config_kinematics[\"collision_spheres\"]\n",
    "    config_kinematics[\"lock_joints\"] = {\"fr3_finger_joint1\": gripper_width, \"fr3_finger_joint2\": gripper_width}\n",
    "\n",
    "    robot_cfg = RobotConfig.from_dict(config_file, tensor_args)\n",
    "    kin_model = CudaRobotModel(robot_cfg.kinematics)\n",
    "    return config_file, kin_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c80a6ff-b2f7-4ae2-bbd1-aaeb2c71fe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, left_kin_model = load_franka_kin_model(0.04)\n",
    "retract_q = left_kin_model.retract_config.cpu().numpy().reshape(1, -1)\n",
    "print(retract_q)\n",
    "publish_clear()\n",
    "publish_robot_trajs(retract_q, 0.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650d36ac-0b8a-4718-a371-93649747de5b",
   "metadata": {},
   "source": [
    "## Load environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2873a2f-ec55-413c-8f47-625844a8d03c",
   "metadata": {},
   "source": [
    "### load place environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6647ceac-7b7d-43fe-a670-e23bf9b45220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from robofab import ROBOFAB_DATA_DIR\n",
    "from robofab.mqtt import publish_world, publish_clear\n",
    "from curobo.geom.types import WorldConfig, Mesh\n",
    "import trimesh\n",
    "def load_place_environment(part_ids = np.arange(12)):\n",
    "    ground_obj_file = ROBOFAB_DATA_DIR + \"/world/ground_with_platform.obj\"\n",
    "    assembly_objs_file = [ROBOFAB_DATA_DIR + f\"/world/tetris/{id}.obj\" for id in part_ids]\n",
    "\n",
    "    ground_obstacle = Mesh(\n",
    "        name=f\"ground\",\n",
    "        pose=[0, 0, 0, 1, 0, 0, 0],\n",
    "        file_path = ground_obj_file,\n",
    "        scale = (1E-3, 1E-3, 1E-3)\n",
    "    )\n",
    "\n",
    "    assembly_obstacles = []\n",
    "    assembly_meshes = []\n",
    "    id = 0\n",
    "    translation = [0.6, 0.1, -0.006]\n",
    "    for file in assembly_objs_file:\n",
    "        assembly_obstacles.append(Mesh(\n",
    "            name=f\"part_{id}\",\n",
    "            pose=[*translation, 1, 0, 0, 0],\n",
    "            file_path = file,\n",
    "            scale = (1, 1, 1)\n",
    "        ))\n",
    "        mesh = trimesh.load(file)\n",
    "        mesh.apply_translation(translation)\n",
    "        assembly_meshes.append(mesh)\n",
    "        id = id + 1\n",
    "            \n",
    "    return assembly_meshes, WorldConfig(\n",
    "       mesh=[*assembly_obstacles, ground_obstacle]\n",
    "    )\n",
    "\n",
    "assembly_meshes, place_world = load_place_environment([2])\n",
    "_, ground_world = load_place_environment([])\n",
    "publish_clear()\n",
    "publish_robot_trajs(retract_q, 0.04)\n",
    "publish_world(place_world, merged = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a74eac-4b83-469f-8574-b6f45f7e9ca7",
   "metadata": {},
   "source": [
    "### load pick environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ea86f4-8804-46d3-b607-4ea38f7bd9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from robofab.pick import create_robot_pick_station\n",
    "# shapes can be [\"S-\", \"S+\", \"S2-\", \"T-\", \"T+\", \"T+2\", \"O\", \"L4-\", \"L4+\", \"L4|-\", \"L4|+\", \"I4\"]\n",
    "pick_world = create_robot_pick_station(voxel_size=0.05, shapes = [\"T+\"])[0]\n",
    "publish_clear()\n",
    "publish_robot_trajs(retract_q, 0.04)\n",
    "publish_world(pick_world[3], merged = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86398922-f4ac-4dd4-b7ce-486d9f8cbcfd",
   "metadata": {},
   "source": [
    "# 2. Compute Place IK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58053547-1a41-4060-be3c-50ac34658766",
   "metadata": {},
   "source": [
    "## 2.1 Compute place poses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7116e9d-da2a-4984-88d8-2b2f7a1ed9f5",
   "metadata": {},
   "source": [
    "### Without predefining gripper z-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933b1608-74cf-4a5d-8f2a-7dc69ae22ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from robofab.place import compute_part_place_pose\n",
    "from robofab.place import poses_to_frames\n",
    "place_poses = compute_part_place_pose(assembly_meshes[0], tool_offset = 0)\n",
    "\n",
    "# render\n",
    "frames = poses_to_frames(place_poses)\n",
    "publish_frames(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e36489-1acf-48b3-8825-936bdd886259",
   "metadata": {},
   "source": [
    "### Predefining the gripper z-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53c7f05-c689-4441-815f-42ea062cc0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_poses_with_zaxis = compute_part_place_pose(assembly_meshes[0], tool_offset = 0, zaxis = np.array([0, 0, -1]))\n",
    "\n",
    "# render\n",
    "frames = poses_to_frames(place_poses)\n",
    "publish_frames(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14913d8b-2242-4010-81a4-1d59012b9cee",
   "metadata": {},
   "source": [
    "## 2.2 Initialize IK Solver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d3cb3f-4922-4d70-a4f4-8b54ea8cb3b9",
   "metadata": {},
   "source": [
    "### initialize IK solver function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a097ddc-2196-45e2-a447-d8bf26018710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from curobo.geom.types import Pose\n",
    "from curobo.wrap.reacher.ik_solver import IKSolver, IKSolverConfig\n",
    "\n",
    "def get_franka_ik_solver(gripper_width=0.04, world_config: WorldConfig = None, num_seeds=50):\n",
    "    config_file, _ = load_franka_kin_model(gripper_width)\n",
    "    robot_cfg = RobotConfig.from_dict(config_file)\n",
    "    ik_config = IKSolverConfig.load_from_robot_config(\n",
    "            robot_cfg,\n",
    "            world_model=world_config,\n",
    "            tensor_args=tensor_args,\n",
    "            use_cuda_graph=True,\n",
    "            rotation_threshold=0.001,\n",
    "            position_threshold=0.001,\n",
    "            num_seeds=num_seeds,\n",
    "            self_collision_check=True,\n",
    "            self_collision_opt=True,\n",
    "            collision_activation_distance= 0.02\n",
    "        )\n",
    "    ik_solver = IKSolver(ik_config)\n",
    "    return ik_solver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802c3db2-9d4f-4e9e-a085-aaad6e88f96b",
   "metadata": {},
   "source": [
    "### initialize Plan IK function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af8c60e-41fd-440e-9e0b-13a5ac9d18a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_poses_by_flag(poses: Pose, flag: torch.tensor):\n",
    "    return Pose(position=poses.position[flag, :], quaternion=poses.quaternion[flag, :])\n",
    "\n",
    "def plan_ik(poses: Pose,\n",
    "            world_config: WorldConfig,\n",
    "            gripper_width: float = 0.04):\n",
    "    ik_solver = get_franka_ik_solver(gripper_width=gripper_width, world_config=world_config)\n",
    "    result = ik_solver.solve_batch(poses)\n",
    "    ik_solver.reset_cuda_graph()\n",
    "    if result.success.any():\n",
    "        flag = result.success\n",
    "        success_qs = result.solution[result.success]\n",
    "        sucess_pose = get_poses_by_flag(poses, flag.flatten())\n",
    "        return (success_qs, sucess_pose, flag.flatten())\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426a6098-5d1e-4760-ab40-9a2006d56db2",
   "metadata": {},
   "source": [
    "### Initialize Plan IK with seed function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59d19e7-e69e-4369-8580-a8ee1e7b05ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from curobo.types.state import JointState\n",
    "def plan_ik_seed_config(poses: Pose,\n",
    "                        world_config: WorldConfig,\n",
    "                        seed_config: JointState,\n",
    "                        gripper_width: float = 0.04):\n",
    "    ik_solver = get_franka_ik_solver(gripper_width=gripper_width, world_config=world_config, num_seeds = 1)\n",
    "    seed_config = seed_config.position.view(1, -1)\n",
    "    result = ik_solver.solve_batch(goal_pose=poses, seed_config=seed_config, num_seeds=1)\n",
    "    if result.success.any():\n",
    "        flag = result.success\n",
    "        success_qs = result.solution[result.success]\n",
    "        sucess_pose = get_poses_by_flag(poses, flag.flatten())\n",
    "        return (success_qs, sucess_pose, flag.flatten())\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996ba419-37fc-4230-9f1d-0a5c04893f85",
   "metadata": {},
   "source": [
    "# 2.3 Plan Place IK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869a9dba-5b14-49c4-a8f1-a4193701cbf3",
   "metadata": {},
   "source": [
    "### Plan place ik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f3be97-3428-48b9-9e71-79bccc7799d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_result = plan_ik(place_poses, place_world, 0.04)\n",
    "\n",
    "# update\n",
    "place_poses = place_result[1]\n",
    "\n",
    "# render\n",
    "publish_clear()\n",
    "publish_robot_trajs(place_result[0].cpu().numpy(), 0.04)\n",
    "frames = poses_to_frames(place_poses)\n",
    "publish_frames(frames)\n",
    "publish_world(place_world, merged = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee867e6-779b-417b-b1d7-adf98bf09d01",
   "metadata": {},
   "source": [
    "### Plan place approach IK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e5ec29-e125-473b-8226-03e5c6ad4ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_approach_poses = place_poses.clone()\n",
    "place_approach_poses.position += torch.tensor([0, 0, 0.1], **tensor_args.as_torch_dict())\n",
    "place_approach_result =  plan_ik(place_approach_poses, place_world, 0.04)\n",
    "\n",
    "# update\n",
    "place_approach_poses = place_approach_result[1]\n",
    "place_poses = get_poses_by_flag(place_poses, place_approach_result[2])\n",
    "print(\"Number of place poses\", place_poses.position.shape[0])\n",
    "\n",
    "# render\n",
    "publish_clear()\n",
    "publish_robot_trajs(place_approach_result[0].cpu().numpy(), 0.04)\n",
    "frames = poses_to_frames(place_approach_poses)\n",
    "publish_frames(frames)\n",
    "publish_world(place_world, merged = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1612e3-d3c3-493f-85a8-caa78d7e0e04",
   "metadata": {},
   "source": [
    "# 3. Compute Pick IK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1521f29-5f93-42ba-91f3-114143ce6939",
   "metadata": {},
   "source": [
    "# 3.1 Compute pick poses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec00e3e-be1a-4e6d-ba28-5c6ca79b7464",
   "metadata": {},
   "source": [
    "### Compute place to pick transformation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad263f1-ff90-4f5f-99f9-53adbed5e80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from robofab.pick import compute_part_transformation_from_place_to_pick\n",
    "# It can have multiple mats for achieving the same effect\n",
    "place_to_pick_mats = compute_part_transformation_from_place_to_pick(assembly_meshes[0], pick_world, voxel_size = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692610a7-ae85-4857-a648-d97812cf8542",
   "metadata": {},
   "source": [
    "### Compute pick frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e08c8b3-ca1d-42c0-8cbf-935d553d9eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# render\n",
    "publish_clear()\n",
    "place_frames = poses_to_frames(place_poses)\n",
    "pick_frames = place_to_pick_mats[0] @ place_frames\n",
    "publish_frames(pick_frames)\n",
    "publish_world(pick_world[3], merged = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c4dd07-d4be-49f3-ba5c-23654fcbca98",
   "metadata": {},
   "source": [
    "### Compute pick poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad3d40b-ff2a-4805-9f1d-27c475a3a68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from curobo.geom.transform import matrix_to_quaternion\n",
    "pick_frames = torch.tensor(pick_frames, **tensor_args.as_torch_dict())\n",
    "pick_poses = Pose(position=pick_frames[:, :3, 3], quaternion=matrix_to_quaternion(pick_frames[:, :3, :3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef80cf4a-e554-4efe-b970-ceaf22028b5e",
   "metadata": {},
   "source": [
    "## 3.2 Compute pick IK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267c2264-4ab2-440d-8648-89572430ac20",
   "metadata": {},
   "source": [
    "### Plan pick ik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26187922-1163-46e5-9e87-e3d84e3d27a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_result = plan_ik(pick_poses, place_world, 0.04)\n",
    "\n",
    "# update\n",
    "pick_poses = pick_result[1]\n",
    "place_poses = get_poses_by_flag(place_poses, pick_result[2])\n",
    "place_approach_poses = get_poses_by_flag(place_approach_poses, pick_result[2])\n",
    "\n",
    "# render\n",
    "publish_clear()\n",
    "publish_robot_trajs(pick_result[0].cpu().numpy(), 0.04)\n",
    "publish_world(pick_world[3], merged = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccfb290-937e-4ed8-b4fc-ca16e18b4a32",
   "metadata": {},
   "source": [
    "### Plan pick approach ik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b62c7e-3a90-422e-aa83-cbc476cdf9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_approach_poses = pick_poses.clone()\n",
    "pick_approach_poses.position += torch.tensor([0, 0, 0.1], **tensor_args.as_torch_dict())\n",
    "pick_approach_result =  plan_ik(pick_approach_poses, pick_world[3], 0.04)\n",
    "\n",
    "# update\n",
    "pick_approach_poses = pick_approach_result[1]\n",
    "pick_poses = get_poses_by_flag(pick_poses, pick_approach_result[2])\n",
    "place_poses = get_poses_by_flag(place_poses, pick_approach_result[2])\n",
    "place_approach_poses = get_poses_by_flag(place_approach_poses, pick_approach_result[2])\n",
    "print(\"Number of pick poses\", place_poses.position.shape[0])\n",
    "\n",
    "# render\n",
    "publish_clear()\n",
    "publish_robot_trajs(pick_approach_result[0].cpu().numpy(), 0.04)\n",
    "publish_world(pick_world[3], merged = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105ae9cf-429d-4c25-8849-4801ab1b9767",
   "metadata": {},
   "source": [
    "# 4. Plan Motions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0919e71f-82c8-45fd-96f9-a1f634799539",
   "metadata": {},
   "source": [
    "## 4.1 Initialize motion solver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559ce27a-d706-4241-9657-2bfb4d906886",
   "metadata": {},
   "source": [
    "### Motion gen configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979ab57f-efbf-4df7-a565-1ae64801c0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from curobo.wrap.reacher.motion_gen import MotionGen, MotionGenConfig, MotionGenPlanConfig\n",
    "from curobo.util.trajectory import InterpolateType\n",
    "\n",
    "def get_franka_motion_gen(gripper_width=0.04, world_config: WorldConfig = None, num_seeds=50):\n",
    "    config_file, _ = load_franka_kin_model(gripper_width)\n",
    "    robot_cfg = RobotConfig.from_dict(config_file)\n",
    "    motion_gen_config = MotionGenConfig.load_from_robot_config(\n",
    "            robot_cfg,\n",
    "            world_model=world_config,\n",
    "            tensor_args=tensor_args,\n",
    "            use_cuda_graph=True,\n",
    "            rotation_threshold=0.05,\n",
    "            position_threshold=0.005,\n",
    "            num_ik_seeds=num_seeds,\n",
    "            num_trajopt_seeds=num_seeds,\n",
    "            interpolation_dt=0.01,\n",
    "            interpolation_steps = 1000,\n",
    "            interpolation_type=InterpolateType.CUBIC,\n",
    "            high_precision=True,\n",
    "            self_collision_check=True,\n",
    "            self_collision_opt=True,\n",
    "            minimize_jerk=True,\n",
    "            collision_activation_distance=0.02)\n",
    "    return MotionGen(motion_gen_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3df577-7913-4321-b245-a8c5ca6c3f33",
   "metadata": {},
   "source": [
    "### Motion gen planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3811e745-e332-4af9-90f4-afdb820061f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from curobo.types.state import JointState\n",
    "def plan_motion_attached_object(start_state: JointState,\n",
    "                                goal_poses: Pose,\n",
    "                                attached_object: Mesh,\n",
    "                                attached_state : JointState,\n",
    "                                world_config: WorldConfig,\n",
    "                                gripper_width: float = 0.04):\n",
    "    \n",
    "    motion_gen = get_franka_motion_gen(world_config=world_config, gripper_width=gripper_width)\n",
    "    place_poses = Pose(position=goal_poses.position.view(1, -1, 3), quaternion=goal_poses.quaternion.view(1, -1, 4))\n",
    "    start_state.joint_names = motion_gen.kinematics.joint_names.copy()\n",
    "\n",
    "    attached_state.joint_names = motion_gen.kinematics.joint_names.copy()\n",
    "    motion_gen.attach_external_objects_to_robot(attached_state,\n",
    "                                                [attached_object],\n",
    "                                                surface_sphere_radius=0.015,\n",
    "                                                link_name=\"attached_object\")\n",
    "\n",
    "    result = motion_gen.plan_goalset(start_state, place_poses, MotionGenPlanConfig(max_attempts=10))\n",
    "    if result.success.any():\n",
    "        qtraj = result.get_interpolated_plan().position\n",
    "        return (qtraj, result.goalset_index.item())\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6139fb6-d500-4f4e-9c89-ff49fcab002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_motion_js_attached_object(start_state: JointState,\n",
    "                                goal_state: JointState,\n",
    "                                attached_object: Mesh,\n",
    "                                attached_state : JointState,\n",
    "                                world_config: WorldConfig,\n",
    "                                gripper_width: float = 0.04):\n",
    "    \n",
    "    motion_gen = get_franka_motion_gen(world_config=world_config, gripper_width=gripper_width)\n",
    "    start_state.joint_names = motion_gen.kinematics.joint_names.copy()\n",
    "    goal_state.joint_names = motion_gen.kinematics.joint_names.copy()\n",
    "    \n",
    "    attached_state.joint_names = motion_gen.kinematics.joint_names.copy()\n",
    "    motion_gen.attach_external_objects_to_robot(attached_state,\n",
    "                                                [attached_object],\n",
    "                                                surface_sphere_radius=0.015,\n",
    "                                                link_name=\"attached_object\")\n",
    "\n",
    "    result = motion_gen.plan_single_js(start_state, goal_state, MotionGenPlanConfig(max_attempts=10))\n",
    "    if result.success.any():\n",
    "        qtraj = result.get_interpolated_plan().position\n",
    "        return qtraj\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17175dd-4b57-42d3-a12c-c9cd2248540d",
   "metadata": {},
   "source": [
    "### Choose one pick-place-approach pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae377278-6b11-4589-8d5b-9a63a767f25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_place_id = 0\n",
    "pick_pose = pick_poses.clone()[pick_place_id]\n",
    "place_pose = place_poses.clone()[pick_place_id]\n",
    "pick_approach_pose = pick_approach_poses.clone()[pick_place_id]\n",
    "place_approach_pose = place_approach_poses.clone()[pick_place_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ff4a9a-6f9d-4cf0-81cd-62023998ca56",
   "metadata": {},
   "source": [
    "## 4.1 Retract -> pick_approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79742ebc-a208-4b29-9b0e-b5500d44e859",
   "metadata": {},
   "source": [
    "### Compute attach objects and states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65bd479-e7c5-4552-92bf-d48304a5d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_result = plan_ik(pick_pose, pick_world[3], 0.04)\n",
    "pick_q = pick_result[0].cpu().numpy().reshape(1, -1)\n",
    "\n",
    "attached_state = JointState.from_position(pick_result[0])\n",
    "attached_object = pick_world[3].mesh[0]\n",
    "start_state = JointState.from_position(left_kin_model.retract_config.view(1, -1), joint_names=left_kin_model.joint_names)\n",
    "\n",
    "attached_object_for_rendering = trimesh.Trimesh(pick_world[1][0].vertices.copy(), pick_world[1][0].faces.copy())\n",
    "T = poses_to_frames(pick_pose).reshape(4, 4)\n",
    "invT = np.linalg.inv(T)\n",
    "attached_object_for_rendering.apply_transform(invT)\n",
    "\n",
    "# render\n",
    "publish_clear()\n",
    "publish_robot_trajs(retract_q, 0.04)\n",
    "publish_grasp_object(attached_object_for_rendering)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da94415-9b59-4e88-b523-869ab1586320",
   "metadata": {},
   "source": [
    "### Plan motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4283be29-6ccb-40b8-a3c3-6d1208286665",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajs_retract_pick_approach_result = plan_motion_attached_object(start_state, pick_approach_pose, attached_object, attached_state, ground_world, 0.02)\n",
    "trajs_retract_pick = trajs_retract_pick_approach_result[0].clone().cpu().numpy()\n",
    "trajs_retract_pick = np.vstack([trajs_retract_pick, pick_q])\n",
    "\n",
    "#render\n",
    "publish_clear()\n",
    "publish_robot_trajs(trajs_retract_pick, 0.04)\n",
    "publish_world(pick_world[3], merged = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f18619-23f0-4966-b90f-360686adb7ca",
   "metadata": {},
   "source": [
    "### Resolve IK Jumping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111b9a6c-a592-4f8d-9f15-c59b55f4249c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_approach_state = JointState.from_position(trajs_retract_pick_approach_result[0][-1], joint_names=left_kin_model.joint_names)\n",
    "pick_result = plan_ik_seed_config(pick_pose, pick_world[3], pick_approach_state, 0.04)\n",
    "pick_q = pick_result[0].cpu().numpy()\n",
    "trajs_retract_pick = trajs_retract_pick_approach_result[0].clone().cpu().numpy()\n",
    "trajs_retract_pick = np.vstack([trajs_retract_pick, pick_q])\n",
    "\n",
    "# render\n",
    "publish_clear()\n",
    "publish_robot_trajs(trajs_retract_pick, 0.04)\n",
    "publish_world(pick_world[3], merged = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27c0d82-5a67-49d7-999a-6ebc643174fb",
   "metadata": {},
   "source": [
    "## 4.2 retract -> place_approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ba826c-2fa9-4f9c-886b-e91425b2bffe",
   "metadata": {},
   "source": [
    "### Compute attach objects and states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d306b3-18a2-4c5c-b35d-a343cde62326",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_result = plan_ik(place_pose, place_world, 0.04)\n",
    "place_q = place_result[0].cpu().numpy().reshape(1, -1)\n",
    "attached_state = JointState.from_position(place_result[0])\n",
    "attached_object = place_world.mesh[0]\n",
    "start_state = JointState.from_position(left_kin_model.retract_config.view(1, -1), joint_names=left_kin_model.joint_names)\n",
    "attached_object_for_rendering = trimesh.Trimesh(assembly_meshes[0].vertices.copy(), assembly_meshes[0].faces.copy())\n",
    "T = poses_to_frames(place_pose).reshape(4, 4)\n",
    "invT = np.linalg.inv(T)\n",
    "attached_object_for_rendering.apply_transform(invT)\n",
    "\n",
    "publish_clear()\n",
    "publish_robot_trajs(retract_q, 0.04)\n",
    "publish_grasp_object(attached_object_for_rendering)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed8ee80-e041-4621-bb1b-8a87dacbd1b6",
   "metadata": {},
   "source": [
    "### Plan motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c607f13-8213-4437-a33c-7cc1a13e4559",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajs_retract_place_approach_result = plan_motion_attached_object(start_state, place_approach_pose, attached_object, attached_state, ground_world, 0.02)\n",
    "trajs_retract_place = trajs_retract_place_approach_result[0].cpu().numpy()\n",
    "trajs_retract_place = np.vstack([trajs_retract_place, place_q])\n",
    "\n",
    "#render\n",
    "publish_clear()\n",
    "publish_robot_trajs(trajs_retract_place, 0.02)\n",
    "publish_grasp_object(attached_object_for_rendering)\n",
    "publish_world(ground_world, merged = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704e8219-5e66-4f9a-94dd-705a16c57402",
   "metadata": {},
   "source": [
    "### Resolve IK Jumping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb80386-b770-4082-b439-eb3eb931f7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_approach_state = JointState.from_position(trajs_retract_place_approach_result[0][-1], joint_names=left_kin_model.joint_names)\n",
    "place_result = plan_ik_seed_config(place_pose, place_world, place_approach_state, 0.04)\n",
    "place_q = place_result[0].cpu().numpy()\n",
    "trajs_retract_place = trajs_retract_place_approach_result[0].clone().cpu().numpy()\n",
    "trajs_retract_place = np.vstack([trajs_retract_place, place_q])\n",
    "\n",
    "# render\n",
    "publish_clear()\n",
    "publish_robot_trajs(trajs_retract_place, 0.02)\n",
    "publish_grasp_object(attached_object_for_rendering)\n",
    "publish_world(ground_world, merged = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7d9f87-6715-49cf-9b54-acbd4550e23e",
   "metadata": {},
   "source": [
    "## 4.2 pick_approach -> place_approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95204da2-031c-43c4-9646-6b9df6ced13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_approach_q = torch.tensor(trajs_retract_pick[-2, :].reshape(1, -1), **tensor_args.as_torch_dict())\n",
    "place_approach_q = torch.tensor(trajs_retract_place[-2, :].reshape(1, -1), **tensor_args.as_torch_dict())\n",
    "start_state = JointState.from_position(pick_approach_q, joint_names=left_kin_model.joint_names)\n",
    "goal_state = JointState.from_position(place_approach_q, joint_names=left_kin_model.joint_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c9857f-d0fd-4387-84db-28bf80ea2253",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajs_pick_place_approach_result = plan_motion_js_attached_object(start_state, goal_state, attached_object, attached_state, ground_world, 0.02)\n",
    "trajs_pick_place = trajs_pick_place_approach_result.cpu().numpy()\n",
    "trajs_pick_place = np.vstack([pick_q, trajs_pick_place, place_q])\n",
    "\n",
    "#render\n",
    "publish_clear()\n",
    "publish_robot_trajs(trajs_pick_place, 0.02)\n",
    "publish_grasp_object(attached_object_for_rendering)\n",
    "publish_world(ground_world, merged = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ada45dc-7da9-4cff-80bd-b154a4effccd",
   "metadata": {},
   "source": [
    "### Complete Animation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b337c0a3-52cb-4d53-a83e-0d99a9fd5623",
   "metadata": {},
   "source": [
    "### Retract to pick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e50ceea-0330-4230-8ee5-e79ad56ac378",
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_clear()\n",
    "publish_robot_trajs(trajs_retract_pick, 0.04)\n",
    "publish_world(pick_world[3], merged = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f4893d-5365-4332-b846-39acb5c20b54",
   "metadata": {},
   "source": [
    "### pick to place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27f87d6-9a99-4aef-b02c-5d72d4098296",
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_clear()\n",
    "publish_robot_trajs(trajs_pick_place, 0.02)\n",
    "publish_grasp_object(attached_object_for_rendering)\n",
    "publish_world(ground_world, merged = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a3c2e5-5f9f-4d25-a4d9-f2187e89a1bd",
   "metadata": {},
   "source": [
    "### place to retract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071c6b8a-d112-493b-b157-85c4ce412203",
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_clear()\n",
    "publish_robot_trajs(trajs_retract_place[::-1], 0.04)\n",
    "publish_world(place_world, merged = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
